{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_MAP = {\n",
    "    'N': 'NOUN',\n",
    "    'V': 'VERB',\n",
    "    'J':'ADJ',\n",
    "    'NNS' : 'NOUN'\n",
    "}\n",
    "\n",
    "TRAIN_DATA = [\n",
    "    (\"I like green eggs\", {'tags': ['N', 'V', 'J', 'NNS']}), \n",
    "    (\"Eat blue ham\", {'tags': ['V', 'J', 'N']}), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(lang='en', output_dir=None, n_iter=3):\n",
    "\n",
    "    nlp = spacy.blank(lang) #Créer un modèle spacy vide pour l'anglais\n",
    "    tagger = nlp.add_pipe(\"tagger\") #Créer un modèle (tagger) qui attribue des tags aux mots d'un texte \n",
    "\n",
    "    for item in TAG_MAP:\n",
    "        tagger.add_label(item) #Ajouter des tags aux tagger\n",
    "\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
    "        print(losses)\n",
    "\n",
    "    test_text = \"I love cats\"\n",
    "    doc = nlp(test_text)\n",
    "    print('Tags', [(t.text, t.tag_, t.pos_) for t in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tagger': 5.29118800163269}\n",
      "{'tagger': 4.324729919433594}\n",
      "{'tagger': 2.966841697692871}\n",
      "Tags [('I', 'N', ''), ('love', 'V', ''), ('cats', 'NNS', '')]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "TRAIN_DATA = [\n",
    "('Who is Shaka Khan?', {\n",
    "    'entities': [(7, 17, 'PERSON')]\n",
    "}),\n",
    "('I like London and Berlin.', {\n",
    "    'entities': [(7, 13, 'LOC'), (18, 24, 'LOC')]\n",
    "}),\n",
    " ('I am learning Python', {\n",
    "    'entities': [(14, 20, 'TECH')]\n",
    "})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=None, output_dir=None, n_iter=100):\n",
    "    \n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "        \n",
    "        if 'ner' not in nlp.pipe_names:\n",
    "            ner = nlp.add_pipe('ner', last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "        else:\n",
    "            ner = nlp.get_pipe('ner')\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "    \n",
    "    # get names of other pipes to disable them during training \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        \n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "                nlp.update(\n",
    "                    [example],\n",
    "                    drop=0.5, # dropout-make it harder to memorise data\n",
    "                    sgd=optimizer, # callable to update weights\n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "            \n",
    "    # test the trained model\n",
    "    doc = nlp('I love Python')\n",
    "    print()\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "{'ner': 13.661589443683624}\n",
      "{'ner': 12.780549049377441}\n",
      "{'ner': 11.718456029891968}\n",
      "{'ner': 10.261194914579391}\n",
      "{'ner': 8.436154402792454}\n",
      "{'ner': 7.5132438987493515}\n",
      "{'ner': 6.195048194378614}\n",
      "{'ner': 6.048486293293536}\n",
      "{'ner': 5.976720348466188}\n",
      "{'ner': 6.699109001085162}\n",
      "{'ner': 5.371995489054825}\n",
      "{'ner': 5.552186889311997}\n",
      "{'ner': 5.176415246911347}\n",
      "{'ner': 4.257470318378182}\n",
      "{'ner': 4.86982959206216}\n",
      "{'ner': 4.734175256508024}\n",
      "{'ner': 4.251351436658297}\n",
      "{'ner': 3.8278260016995773}\n",
      "{'ner': 3.421245729901784}\n",
      "{'ner': 3.133431753663899}\n",
      "{'ner': 5.880396975063604}\n",
      "{'ner': 4.73313140026039}\n",
      "{'ner': 4.033965459280807}\n",
      "{'ner': 3.34562244249355}\n",
      "{'ner': 3.362248985795304}\n",
      "{'ner': 1.792185184955997}\n",
      "{'ner': 1.662567946971194}\n",
      "{'ner': 4.646769463630051}\n",
      "{'ner': 1.810014566163602}\n",
      "{'ner': 2.8037084164944583}\n",
      "{'ner': 2.328709575316255}\n",
      "{'ner': 0.8061871854944813}\n",
      "{'ner': 1.8794366380681624}\n",
      "{'ner': 1.3388374271534043}\n",
      "{'ner': 0.0940337553091017}\n",
      "{'ner': 0.67281117985946}\n",
      "{'ner': 0.14437908974697725}\n",
      "{'ner': 0.06868631820418503}\n",
      "{'ner': 0.006556991892760895}\n",
      "{'ner': 0.003889286487775423}\n",
      "{'ner': 0.09513099128319918}\n",
      "{'ner': 0.3697757524921908}\n",
      "{'ner': 0.07697607083437585}\n",
      "{'ner': 3.98758974116588e-05}\n",
      "{'ner': 0.00010593514642503512}\n",
      "{'ner': 0.0015553222863173507}\n",
      "{'ner': 0.0011254681248181401}\n",
      "{'ner': 0.0004917997193442683}\n",
      "{'ner': 7.0784356791519825e-06}\n",
      "{'ner': 0.18922055241099256}\n",
      "{'ner': 5.212835919740727e-05}\n",
      "{'ner': 0.0008097554050824868}\n",
      "{'ner': 0.0015626061193592103}\n",
      "{'ner': 7.981468095229171e-07}\n",
      "{'ner': 0.034796737641638945}\n",
      "{'ner': 0.0001636551738860818}\n",
      "{'ner': 0.0029524022675094814}\n",
      "{'ner': 0.0011957067755643527}\n",
      "{'ner': 0.006704236120883729}\n",
      "{'ner': 0.015650640405181087}\n",
      "{'ner': 9.023290853172943e-07}\n",
      "{'ner': 1.67230816198291e-05}\n",
      "{'ner': 0.001620039106598731}\n",
      "{'ner': 1.3588197240089434e-06}\n",
      "{'ner': 0.0005595179244278715}\n",
      "{'ner': 9.153886050693525e-07}\n",
      "{'ner': 3.0653452310666927e-07}\n",
      "{'ner': 3.234941569315522e-05}\n",
      "{'ner': 1.930672155841381e-06}\n",
      "{'ner': 5.385231224008002e-06}\n",
      "{'ner': 1.735768716542324e-07}\n",
      "{'ner': 6.426633304166522e-06}\n",
      "{'ner': 1.5178988803942704e-05}\n",
      "{'ner': 2.1179596113807266e-07}\n",
      "{'ner': 0.001029605981568621}\n",
      "{'ner': 1.7582695836153998e-05}\n",
      "{'ner': 2.2836081087766367e-08}\n",
      "{'ner': 4.084470953232485e-09}\n",
      "{'ner': 2.2672138592224016e-07}\n",
      "{'ner': 0.00034351496447387485}\n",
      "{'ner': 6.818618201950417e-09}\n",
      "{'ner': 1.3323873191483489e-08}\n",
      "{'ner': 2.57135236206483e-07}\n",
      "{'ner': 4.2044074440602754e-07}\n",
      "{'ner': 3.288250631335461e-08}\n",
      "{'ner': 1.4037600408736526e-08}\n",
      "{'ner': 8.726651454819631e-10}\n",
      "{'ner': 0.031202227812468918}\n",
      "{'ner': 7.143701218163096e-09}\n",
      "{'ner': 6.910945119525519e-07}\n",
      "{'ner': 3.4089264994200827e-07}\n",
      "{'ner': 4.303254240367344e-09}\n",
      "{'ner': 0.007559031836853377}\n",
      "{'ner': 4.131634950770727e-08}\n",
      "{'ner': 3.7366960572195015e-05}\n",
      "{'ner': 1.7951090610701708e-07}\n",
      "{'ner': 6.68471952628556e-07}\n",
      "{'ner': 3.0052741686134564e-08}\n",
      "{'ner': 1.0827947318988158e-06}\n",
      "{'ner': 2.2171689988666398e-06}\n",
      "\n",
      "Entities [('Python', 'TECH')]\n",
      "Tokens [('I', '', 2), ('love', '', 2), ('Python', 'TECH', 3)]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
