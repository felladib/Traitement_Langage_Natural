{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # ou \"en_core_web_sm\" pour l'anglais\n",
    "stop_words = set(stopwords.words(\"english\"))  # Changez pour \"english\" si nécessaire\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and token.text.lower() not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "paragraph1 = \"\"\" Machine learning (ML) is a branch of computer science that focuses on using data and \n",
    "                 algorithms to enable AI to imitate the way that humans learn, gradually improving its accuracy.\n",
    "                 A Decision Process: In general, machine learning algorithms are used to make a prediction or\n",
    "                 classification. Based on some input data, which can be labeled or unlabeled, your algorithm will \n",
    "                 produce an estimate about a pattern in the data.\n",
    "                 An Error Function: An error function evaluates the prediction of the model. If there are known examples, \n",
    "                 an error function can make a comparison to assess the accuracy of the model.\n",
    "                 A Model Optimization Process: If the model can fit better to the data points in the training set, \n",
    "                 then weights are adjusted to reduce the discrepancy between the known example and the model estimate. \n",
    "                 The algorithm will repeat this iterative “evaluate and optimize” process, updating weights autonomously \n",
    "                 until a threshold of accuracy has been met.\n",
    "\"\"\"\n",
    "\n",
    "paragraph2 = \"\"\" A neural network is a machine learning program, or model, that makes decisions in a manner similar to \n",
    "                 the human brain, by using processes that mimic the way biological neurons work together to identify \n",
    "                 phenomena, weigh options and arrive at conclusions. \n",
    "                 Every neural network consists of layers of nodes, or artificial neurons—an input layer, one or more \n",
    "                 hidden layers, and an output layer. Each node connects to others, and has its own associated weight \n",
    "                 and threshold. If the output of any individual node is above the specified threshold value, that node \n",
    "                 is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the \n",
    "                 next layer of the network.\n",
    "                 Neural networks rely on training data to learn and improve their accuracy over time. Once they are \n",
    "                 fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, \n",
    "                 allowing us to classify and cluster data at a high velocity. Tasks in speech recognition or image \n",
    "                 recognition can take minutes versus hours when compared to the manual identification by human experts. \n",
    "                 One of the best-known examples of a neural network is Google’s search algorithm. \n",
    "                 Neural networks are sometimes called artificial neural networks (ANNs) or \n",
    "                 simulated neural networks (SNNs). They are a subset of machine learning, and at the heart of \n",
    "                 deep learning models. \n",
    "\"\"\"\n",
    "paragraph3 = \"\"\" Deep learning is a subset of machine learning that uses multilayered neural networks, \n",
    "                 called deep neural networks, to simulate the complex decision-making power of the human brain. \n",
    "                 Some form of deep learning powers most of the artificial intelligence (AI) applications in our \n",
    "                 lives today.\n",
    "                 The chief difference between deep learning and machine learning is the structure of the underlying \n",
    "                 neural network architecture. “Nondeep,” traditional machine learning models use simple neural networks \n",
    "                 with one or two computational layers. Deep learning models use three or more layers—but typically \n",
    "                 hundreds or thousands of layers—to train the models.\n",
    "                 While supervised learning models require structured, labeled input data to make accurate outputs, \n",
    "                 deep learning models can use unsupervised learning. With unsupervised learning, deep learning models \n",
    "                 can extract the characteristics, features and relationships they need to make accurate outputs from raw,\n",
    "                 unstructured data. Additionally, these models can even evaluate and refine their outputs for increased \n",
    "                 precision.\n",
    "                 Deep learning is an aspect of data science that drives many applications and services that improve \n",
    "                 automation, performing analytical and physical tasks without human intervention. This enables many \n",
    "                 everyday products and services—such as digital assistants, voice-enabled TV remotes, credit card fraud \n",
    "                 detection, self-driving cars and generative AI.   \n",
    "\"\"\"\n",
    "\n",
    "corpus = [paragraph1, paragraph2, paragraph3]\n",
    "\n",
    "cleaned_corpus = [preprocess_text(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num_topic = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thèmes LDA :\n",
      "Thème 0: ['learning', 'model', 'network', 'neural', 'deep', 'layer', 'machine', 'use', 'datum', 'make']\n",
      "Thème 1: ['learning', 'model', 'datum', 'network', 'neural', 'layer', 'algorithm', 'use', 'accuracy', 'make']\n",
      "Thème 2: ['network', 'neural', 'datum', 'layer', 'model', 'artificial', 'learning', 'accuracy', 'output', 'machine']\n",
      "\n",
      "Thèmes LSA :\n",
      "Thème 0: ['learning', 'network', 'model', 'neural', 'layer', 'deep', 'datum', 'use', 'machine', 'output']\n",
      "Thème 1: ['network', 'learning', 'neural', 'layer', 'deep', 'model', 'node', 'artificial', 'next', 'neuron']\n",
      "Thème 2: ['algorithm', 'accuracy', 'model', 'error', 'estimate', 'prediction', 'function', 'datum', 'example', 'weight']\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Préparation des données\n",
    "texts = [doc.split() for doc in cleaned_corpus]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus_gensim = [dictionary.doc2bow(text) for text in texts]\n",
    "num_topics = 3\n",
    "\n",
    "# Modèle LDA\n",
    "lda_model = LdaModel(corpus=corpus_gensim, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "# Modèle LSA\n",
    "lsa_model = LsiModel(corpus=corpus_gensim, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "# Affichage des thèmes\n",
    "print(\"Thèmes LDA :\")\n",
    "for idx, topic in lda_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print(f\"Thème {idx}: {[word for word, _ in topic]}\")\n",
    "\n",
    "print(\"\\nThèmes LSA :\")\n",
    "for idx, topic in lsa_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print(f\"Thème {idx}: {[word for word, _ in topic]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohérence LDA : 0.4604710729205274\n",
      "Cohérence LSA : 0.8405789185965551\n"
     ]
    }
   ],
   "source": [
    "# Calcul de la cohérence pour LDA\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Cohérence LDA : {coherence_lda}\")\n",
    "\n",
    "# Calcul de la cohérence pour LSA\n",
    "coherence_model_lsa = CoherenceModel(model=lsa_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lsa = coherence_model_lsa.get_coherence()\n",
    "print(f\"Cohérence LSA : {coherence_lsa}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num_topic = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thèmes LDA :\n",
      "Thème 0: ['learning', 'model', 'deep', 'network', 'neural', 'use', 'layer', 'datum', 'output', 'machine']\n",
      "Thème 1: ['learning', 'model', 'deep', 'datum', 'network', 'make', 'human', 'use', 'output', 'algorithm']\n",
      "Thème 2: ['network', 'neural', 'learning', 'layer', 'datum', 'model', 'artificial', 'output', 'neuron', 'node']\n",
      "Thème 3: ['model', 'algorithm', 'datum', 'accuracy', 'learning', 'use', 'make', 'evaluate', 'estimate', 'process']\n",
      "Thème 4: ['learning', 'model', 'use', 'datum', 'deep', 'algorithm', 'make', 'neural', 'machine', 'accuracy']\n",
      "Thème 5: ['network', 'neural', 'layer', 'datum', 'learning', 'node', 'artificial', 'model', 'machine', 'output']\n",
      "Thème 6: ['learning', 'datum', 'model', 'network', 'layer', 'algorithm', 'use', 'neural', 'know', 'accuracy']\n",
      "\n",
      "Thèmes LSA :\n",
      "Thème 0: ['learning', 'network', 'model', 'neural', 'layer', 'deep', 'datum', 'use', 'machine', 'output']\n",
      "Thème 1: ['network', 'learning', 'neural', 'layer', 'deep', 'model', 'node', 'artificial', 'next', 'neuron']\n",
      "Thème 2: ['algorithm', 'accuracy', 'model', 'estimate', 'error', 'function', 'prediction', 'datum', 'weight', 'example']\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Préparation des données\n",
    "texts = [doc.split() for doc in cleaned_corpus]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus_gensim = [dictionary.doc2bow(text) for text in texts]\n",
    "num_topics = 7\n",
    "\n",
    "# Modèle LDA\n",
    "lda_model = LdaModel(corpus=corpus_gensim, id2word=dictionary, num_topics=num_topics, passes=10, random_state=42)\n",
    "\n",
    "# Modèle LSA\n",
    "lsa_model = LsiModel(corpus=corpus_gensim, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "#  Affichage des thèmes\n",
    "print(\"Thèmes LDA :\")\n",
    "for idx, topic in lda_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print(f\"Thème {idx}: {[word for word, _ in topic]}\")\n",
    "\n",
    "print(\"\\nThèmes LSA :\")\n",
    "for idx, topic in lsa_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print(f\"Thème {idx}: {[word for word, _ in topic]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohérence LDA : 0.440094150629418\n",
      "Cohérence LSA : 0.8384286305451871\n"
     ]
    }
   ],
   "source": [
    "# Calcul de la cohérence pour LDA\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Cohérence LDA : {coherence_lda}\")\n",
    "\n",
    "# Calcul de la cohérence pour LSA\n",
    "coherence_model_lsa = CoherenceModel(model=lsa_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lsa = coherence_model_lsa.get_coherence()\n",
    "print(f\"Cohérence LSA : {coherence_lsa}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num_topic = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thèmes LDA :\n",
      "Thème 0: ['learning', 'network', 'neural', 'model', 'layer', 'datum', 'deep', 'use', 'machine', 'output']\n",
      "Thème 1: ['model', 'algorithm', 'datum', 'accuracy', 'learning', 'make', 'use', 'process', 'know', 'example']\n",
      "\n",
      "Thèmes LSA :\n",
      "Thème 0: ['learning', 'network', 'model', 'neural', 'layer', 'deep', 'datum', 'use', 'machine', 'output']\n",
      "Thème 1: ['network', 'learning', 'neural', 'layer', 'deep', 'model', 'node', 'artificial', 'next', 'neuron']\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Préparation des données\n",
    "texts = [doc.split() for doc in cleaned_corpus]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus_gensim = [dictionary.doc2bow(text) for text in texts]\n",
    "num_topics = 2\n",
    "\n",
    "# Modèle LDA\n",
    "lda_model = LdaModel(corpus=corpus_gensim, id2word=dictionary, num_topics=num_topics, passes=10, random_state=42)\n",
    "\n",
    "# Modèle LSA\n",
    "lsa_model = LsiModel(corpus=corpus_gensim, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "#  Affichage des thèmes\n",
    "print(\"Thèmes LDA :\")\n",
    "for idx, topic in lda_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print(f\"Thème {idx}: {[word for word, _ in topic]}\")\n",
    "\n",
    "print(\"\\nThèmes LSA :\")\n",
    "for idx, topic in lsa_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    print(f\"Thème {idx}: {[word for word, _ in topic]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohérence LDA : 0.4618991753139834\n",
      "Cohérence LSA : 0.9195729277570108\n"
     ]
    }
   ],
   "source": [
    "# Calcul de la cohérence pour LDA\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Cohérence LDA : {coherence_lda}\")\n",
    "\n",
    "# Calcul de la cohérence pour LSA\n",
    "coherence_model_lsa = CoherenceModel(model=lsa_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lsa = coherence_model_lsa.get_coherence()\n",
    "print(f\"Cohérence LSA : {coherence_lsa}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_vis = pyLDAvis.gensim.prepare(lda_model, corpus_gensim, dictionary)\n",
    "pyLDAvis.save_html(lda_vis, 'lda_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
