{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\linai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\linai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. LOAD AND PREPROCESS DATA\n",
    "# Assume spam_ham_dataset is a CSV file with 'text' and 'label' columns\n",
    "# 'label': 1 = spam, 0 = not spam\n",
    "data = pd.read_csv(\"spam_ham_dataset.csv\")  \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label_num\n",
       "0     Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1     Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2     Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3     Subject: photoshop , windows , office . cheap ...          1\n",
       "4     Subject: re : indian springs\\r\\nthis deal is t...          0\n",
       "...                                                 ...        ...\n",
       "5166  Subject: put the 10 on the ft\\r\\nthe transport...          0\n",
       "5167  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...          0\n",
       "5168  Subject: calpine daily gas nomination\\r\\n>\\r\\n...          0\n",
       "5169  Subject: industrial worksheets for august 2000...          0\n",
       "5170  Subject: important online banking alert\\r\\ndea...          1\n",
       "\n",
       "[5171 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 0','label'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject enron methanol meter follow note gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject hpl nom january see attached file hpln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject neon retreat ho ho ho around wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject indian springs deal book teco pvr reve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject put ft transport volumes decreased con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject following noms hpl take extra mmcf wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject calpine daily gas nomination julie men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject industrial worksheets august activity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject important online banking alert dear va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label_num  \\\n",
       "0     Subject: enron methanol ; meter # : 988291\\r\\n...          0   \n",
       "1     Subject: hpl nom for january 9 , 2001\\r\\n( see...          0   \n",
       "2     Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0   \n",
       "3     Subject: photoshop , windows , office . cheap ...          1   \n",
       "4     Subject: re : indian springs\\r\\nthis deal is t...          0   \n",
       "...                                                 ...        ...   \n",
       "5166  Subject: put the 10 on the ft\\r\\nthe transport...          0   \n",
       "5167  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...          0   \n",
       "5168  Subject: calpine daily gas nomination\\r\\n>\\r\\n...          0   \n",
       "5169  Subject: industrial worksheets for august 2000...          0   \n",
       "5170  Subject: important online banking alert\\r\\ndea...          1   \n",
       "\n",
       "                                             clean_text  \n",
       "0     subject enron methanol meter follow note gave ...  \n",
       "1     subject hpl nom january see attached file hpln...  \n",
       "2     subject neon retreat ho ho ho around wonderful...  \n",
       "3     subject photoshop windows office cheap main tr...  \n",
       "4     subject indian springs deal book teco pvr reve...  \n",
       "...                                                 ...  \n",
       "5166  subject put ft transport volumes decreased con...  \n",
       "5167  subject following noms hpl take extra mmcf wee...  \n",
       "5168  subject calpine daily gas nomination julie men...  \n",
       "5169  subject industrial worksheets august activity ...  \n",
       "5170  subject important online banking alert dear va...  \n",
       "\n",
       "[5171 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(\"\\d+\", \"\", text)  # Remove numbers\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['clean_text'] = data['text'].apply(preprocess_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_num\n",
       "0    3672\n",
       "1    1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X = data['clean_text']\n",
    "y = data['label_num']  # Use label_num as the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bag of Words (BOW) ---\n",
      "\n",
      "BOW Results:\n",
      "Accuracy: 0.9806763285024155\n",
      "Confusion Matrix:\n",
      " [[727  15]\n",
      " [  5 288]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       742\n",
      "           1       0.95      0.98      0.97       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. VECTORIZATION AND MODELLING\n",
    "\n",
    "## A. Bag of Words (BOW)\n",
    "print(\"--- Bag of Words (BOW) ---\")\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
    "X_test_bow = vectorizer_bow.transform(X_test)\n",
    "\n",
    "# Model with LogisticRegression\n",
    "model_bow = LogisticRegression(max_iter=1000)\n",
    "model_bow.fit(X_train_bow, y_train)\n",
    "print(\"\\nBOW Results:\")\n",
    "evaluate_model(model_bow, X_test_bow, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "donne des résultats solides, surtout pour des textes courts\n",
    "Avantage : Simple et rapide à mettre en œuvre.\n",
    "Inconvénient : Ne capture pas la sémantique (le sens des mots) et ne tient pas compte de l'ordre des mots.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF ---\n",
      "\n",
      "TF-IDF Results:\n",
      "Accuracy: 0.9855072463768116\n",
      "Confusion Matrix:\n",
      " [[731  11]\n",
      " [  4 289]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       742\n",
      "           1       0.96      0.99      0.97       293\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.98      0.99      0.98      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## B. TF-IDF\n",
    "print(\"\\n--- TF-IDF ---\")\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "# Model with LogisticRegression\n",
    "model_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "print(\"\\nTF-IDF Results:\")\n",
    "evaluate_model(model_tfidf, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     \n",
    "TF-IDF pondère les mots importants, ce qui améliore la performance.\n",
    "Avantage : Réduit l'impact des mots fréquents sans signification\n",
    "Inconvénient : comme BoW, basé sur des mots individuels, pas sur leur contexte.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Word2Vec ---\n",
      "\n",
      "Word2Vec Results:\n",
      "Accuracy: 0.9806763285024155\n",
      "Confusion Matrix:\n",
      " [[736   6]\n",
      " [ 14 279]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       742\n",
      "           1       0.98      0.95      0.97       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.97      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## C. Word2Vec\n",
    "print(\"\\n--- Word2Vec ---\")\n",
    "X_train_tokens = [text.split() for text in X_train]\n",
    "X_test_tokens = [text.split() for text in X_test]\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=350, window=10, min_count=1, workers=4)\n",
    "w2v_model.train(X_train_tokens, total_examples=w2v_model.corpus_count, epochs=150)\n",
    "\n",
    "# Function to convert text to Word2Vec vector\n",
    "def text_to_w2v(tokens, model):\n",
    "    vector = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vector, axis=0) if vector else np.zeros(100)\n",
    "\n",
    "X_train_w2v = np.array([text_to_w2v(tokens, w2v_model) for tokens in X_train_tokens])\n",
    "X_test_w2v = np.array([text_to_w2v(tokens, w2v_model) for tokens in X_test_tokens])\n",
    "\n",
    "# Model with LogisticRegression\n",
    "model_w2v = LogisticRegression(max_iter=500000)\n",
    "model_w2v.fit(X_train_w2v, y_train)\n",
    "print(\"\\nWord2Vec Results:\")\n",
    "evaluate_model(model_w2v, X_test_w2v, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   \n",
    "Word2Vec capture la sémantique des mots, ce qui est utile pour des textes riches.\n",
    "Avantage : Représentation vectorielle des mots basée sur leur contexte.\n",
    "Inconvénient : Nécessite plus de données pour être efficace.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    \n",
    "Paramètre dm (Distributed Memory)\n",
    "dm = 1 \n",
    "    Chaque document est représenté par un vecteur unique.\n",
    "    Le modèle utilise ce vecteur avec les vecteurs des mots voisins pour prédire un mot manquant dans une fenêtre donnée.\n",
    "    Cela permet de capturer le contexte sémantique des documents et des mots \n",
    "    Exemple simplifié :\n",
    "\n",
    "    Phrase : \"Le chat dort sur le tapis\"\n",
    "    Pour prédire \"tapis\", le modèle utilise :\n",
    "    Le vecteur du document\n",
    "    Les mots voisins : \"chat\", \"dort\", \"sur\"\n",
    "\n",
    "\n",
    "dm = 0\n",
    "    Le modèle utilise uniquement le vecteur du document pour prédire des mots aléatoires présents dans le document.\n",
    "    Contrairement à DM, il ignore complètement les vecteurs des mots voisins et le contexte local.\n",
    "\n",
    "    Exemple simplifié :\n",
    "\n",
    "    Phrase : \"Le chat dort sur le tapis\"\n",
    "    Le modèle prend le vecteur du document et prédit des mots comme \"chat\", \"tapis\" sans se soucier de leur position.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc2Vec ---\n",
      "\n",
      "Doc2Vec Results:\n",
      "Accuracy: 0.9594202898550724\n",
      "Confusion Matrix:\n",
      " [[708  34]\n",
      " [  8 285]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       742\n",
      "           1       0.89      0.97      0.93       293\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.94      0.96      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## D. Doc2Vec\n",
    "print(\"\\n--- Doc2Vec ---\")\n",
    "X_train_tagged = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(X_train)]\n",
    "X_test_tagged = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(X_test)]\n",
    "\n",
    "# Train Doc2Vec model \n",
    "d2v_model = Doc2Vec(vector_size=350, window=10, min_count=1, workers=4, epochs=150, dm=0)\n",
    "\n",
    "d2v_model.build_vocab(X_train_tagged)\n",
    "d2v_model.train(X_train_tagged, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "\n",
    "# Convert text to Doc2Vec vectors\n",
    "X_train_d2v = np.array([d2v_model.infer_vector(text.split()) for text in X_train])\n",
    "X_test_d2v = np.array([d2v_model.infer_vector(text.split()) for text in X_test])\n",
    "\n",
    "# Model with LogisticRegression\n",
    "model_d2v = LogisticRegression(max_iter=500000)\n",
    "model_d2v.fit(X_train_d2v, y_train)\n",
    "print(\"\\nDoc2Vec Results:\")\n",
    "evaluate_model(model_d2v, X_test_d2v, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc2Vec ---\n",
      "\n",
      "Doc2Vec Results:\n",
      "Accuracy: 0.9671497584541063\n",
      "Confusion Matrix:\n",
      " [[714  28]\n",
      " [  6 287]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       742\n",
      "           1       0.91      0.98      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.97      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## D. Doc2Vec\n",
    "print(\"\\n--- Doc2Vec ---\")\n",
    "X_train_tagged = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(X_train)]\n",
    "X_test_tagged = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(X_test)]\n",
    "\n",
    "# Train Doc2Vec model \n",
    "d2v_model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=100, dm=0)\n",
    "d2v_model.build_vocab(X_train_tagged)\n",
    "d2v_model.train(X_train_tagged, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "\n",
    "# Convert text to Doc2Vec vectors\n",
    "X_train_d2v = np.array([d2v_model.infer_vector(text.split()) for text in X_train])\n",
    "X_test_d2v = np.array([d2v_model.infer_vector(text.split()) for text in X_test])\n",
    "\n",
    "# Model with LogisticRegression\n",
    "model_d2v = LogisticRegression(max_iter=500000)\n",
    "model_d2v.fit(X_train_d2v, y_train)\n",
    "print(\"\\nDoc2Vec Results:\")\n",
    "evaluate_model(model_d2v, X_test_d2v, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Doc2Vec ---\n",
      "\n",
      "Doc2Vec Results:\n",
      "Accuracy: 0.8859903381642512\n",
      "Confusion Matrix:\n",
      " [[654  88]\n",
      " [ 30 263]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       742\n",
      "           1       0.75      0.90      0.82       293\n",
      "\n",
      "    accuracy                           0.89      1035\n",
      "   macro avg       0.85      0.89      0.87      1035\n",
      "weighted avg       0.90      0.89      0.89      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## D. Doc2Vec\n",
    "print(\"\\n--- Doc2Vec ---\")\n",
    "X_train_tagged = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(X_train)]\n",
    "X_test_tagged = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(X_test)]\n",
    "\n",
    "# Train Doc2Vec model \n",
    "d2v_model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=100, dm=1)\n",
    "d2v_model.build_vocab(X_train_tagged)\n",
    "d2v_model.train(X_train_tagged, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "\n",
    "# Convert text to Doc2Vec vectors\n",
    "X_train_d2v = np.array([d2v_model.infer_vector(text.split()) for text in X_train])\n",
    "X_test_d2v = np.array([d2v_model.infer_vector(text.split()) for text in X_test])\n",
    "\n",
    "# Model with LogisticRegression\n",
    "model_d2v = LogisticRegression(max_iter=500000)\n",
    "model_d2v.fit(X_train_d2v, y_train)\n",
    "print(\"\\nDoc2Vec Results:\")\n",
    "evaluate_model(model_d2v, X_test_d2v, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    \n",
    "Doc2Vec est moins performant que BOW et TF-IDF dans ce cas.\n",
    "\n",
    "Le modèle DBOW (Distributed Bag of Words : dm = 0) est meilleur que le modèle DM (Distributed Memory : dm = 1), \n",
    "car il est plus adapté à des petits datasets.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amélioration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1- Enrichissement des données : Ajouter plus de données pour entraîner Word2Vec et Doc2Vec.\n",
    "\n",
    "2- Ajustement des hyperparamètres :\n",
    "Pour Word2Vec et Doc2Vec :\n",
    "    - Ajuster vector_size, window, epochs, et min_count.\n",
    "    - Tester d'autres classifieurs ceux basé sur les réseaux de neurones.\n",
    "\n",
    "3- Combinaison : Fusionner TF-IDF et Word2Vec, utiliser des modèles d'ensemble.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
